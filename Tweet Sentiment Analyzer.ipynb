{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A tutorial on how to build Tweet Sentiment Analyser"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install torch, transformers and the datasets library\n",
    "!pip install torch \"transformers[sentencepiece]\" datasets --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the DVCLive Libraries\n",
    "!pip install dvc dvclive --quiet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the datasets library\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/Users/pupa/.cache/huggingface/datasets/zeroshot___csv/zeroshot--twitter-financial-news-sentiment-ccca0f3c622c5b67/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fe1094c2a045c49a39eb015d08e12f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download the dataset\n",
    "# We will use zeroshot/twitter-financial-news-sentiment\n",
    "dataset = load_dataset(\"zeroshot/twitter-financial-news-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 9543\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2388\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$BYND - JPMorgan reels in expectations on Beyo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$CCL $RCL - Nomura points to bookings weakness...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$CX - Cemex cut at Credit Suisse, J.P. Morgan ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$ESS: BTIG Research cuts to Neutral https://t....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$FNKO - Funko slides after Piper Jaffray PT cu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9538</th>\n",
       "      <td>The Week's Gainers and Losers on the Stoxx Eur...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9539</th>\n",
       "      <td>Tupperware Brands among consumer gainers; Unil...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9540</th>\n",
       "      <td>vTv Therapeutics leads healthcare gainers; Myo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9541</th>\n",
       "      <td>WORK, XPO, PYX and AMKR among after hour movers</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9542</th>\n",
       "      <td>YNDX, I, QD and OESX among tech movers</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9543 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     $BYND - JPMorgan reels in expectations on Beyo...      0\n",
       "1     $CCL $RCL - Nomura points to bookings weakness...      0\n",
       "2     $CX - Cemex cut at Credit Suisse, J.P. Morgan ...      0\n",
       "3     $ESS: BTIG Research cuts to Neutral https://t....      0\n",
       "4     $FNKO - Funko slides after Piper Jaffray PT cu...      0\n",
       "...                                                 ...    ...\n",
       "9538  The Week's Gainers and Losers on the Stoxx Eur...      2\n",
       "9539  Tupperware Brands among consumer gainers; Unil...      2\n",
       "9540  vTv Therapeutics leads healthcare gainers; Myo...      2\n",
       "9541    WORK, XPO, PYX and AMKR among after hour movers      2\n",
       "9542             YNDX, I, QD and OESX among tech movers      2\n",
       "\n",
       "[9543 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the dataset as a pandas dataframe\n",
    "dataset[\"train\"].to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a pre-trained model from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pytorch and transformers library\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "\n",
    "# Import the DVCLiveCallback for Huggingface\n",
    "from dvclive.huggingface import DVCLiveCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set PyTorch device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([3, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the tokenizer and the model\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3, ignore_mismatched_sizes=True)\n",
    "model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune the model on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /Users/pupa/.cache/huggingface/datasets/zeroshot___csv/zeroshot--twitter-financial-news-sentiment-ccca0f3c622c5b67/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-75996fe1684ce53e.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /Users/pupa/.cache/huggingface/datasets/zeroshot___csv/zeroshot--twitter-financial-news-sentiment-ccca0f3c622c5b67/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-600080428201e9a1.arrow\n"
     ]
    }
   ],
   "source": [
    "# Prepare the dataset for training\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the trainer library\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the initial layers of the model untrainable\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the training arguments and only train the last layer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=32,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,                # log & save weights each logging_steps\n",
    "    use_mps_device=True              # use Apple's Metal Performance Shaders\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                                      # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                               # training arguments, defined above\n",
    "    train_dataset=tokenized_dataset[\"train\"],         # training dataset\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],     # evaluation dataset\n",
    "    data_collator=data_collator,                      # data collator\n",
    "    tokenizer=tokenizer,                              # tokenizer\n",
    "    callbacks=[DVCLiveCallback(save_dvc_exp=True)],   # DVC callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pupa/sarg/experiment-tracking-dvc/venv/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d317e762831246c8a9d6f9c89fe53b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/897 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1985, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.03}\n",
      "{'loss': 1.1863, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.07}\n",
      "{'loss': 1.1725, 'learning_rate': 3e-06, 'epoch': 0.1}\n",
      "{'loss': 1.1639, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.13}\n",
      "{'loss': 1.1571, 'learning_rate': 5e-06, 'epoch': 0.17}\n",
      "{'loss': 1.1254, 'learning_rate': 6e-06, 'epoch': 0.2}\n",
      "{'loss': 1.0804, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.23}\n",
      "{'loss': 1.0412, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.27}\n",
      "{'loss': 1.0049, 'learning_rate': 9e-06, 'epoch': 0.3}\n",
      "{'loss': 0.9778, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 0.9651, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.37}\n",
      "{'loss': 0.9437, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "{'loss': 0.9115, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.43}\n",
      "{'loss': 0.8695, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.47}\n",
      "{'loss': 0.8523, 'learning_rate': 1.5e-05, 'epoch': 0.5}\n",
      "{'loss': 0.797, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.54}\n",
      "{'loss': 0.8476, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.57}\n",
      "{'loss': 0.8307, 'learning_rate': 1.8e-05, 'epoch': 0.6}\n",
      "{'loss': 0.7858, 'learning_rate': 1.9e-05, 'epoch': 0.64}\n",
      "{'loss': 0.805, 'learning_rate': 2e-05, 'epoch': 0.67}\n",
      "{'loss': 0.8176, 'learning_rate': 2.1e-05, 'epoch': 0.7}\n",
      "{'loss': 0.8001, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.74}\n",
      "{'loss': 0.7594, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.77}\n",
      "{'loss': 0.7925, 'learning_rate': 2.4e-05, 'epoch': 0.8}\n",
      "{'loss': 0.7756, 'learning_rate': 2.5e-05, 'epoch': 0.84}\n",
      "{'loss': 0.7546, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.87}\n",
      "{'loss': 0.7235, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.9}\n",
      "{'loss': 0.7606, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.94}\n",
      "{'loss': 0.7307, 'learning_rate': 2.9e-05, 'epoch': 0.97}\n",
      "{'loss': 0.7133, 'learning_rate': 3e-05, 'epoch': 1.0}\n",
      "{'loss': 0.7521, 'learning_rate': 3.1e-05, 'epoch': 1.04}\n",
      "{'loss': 0.7365, 'learning_rate': 3.2000000000000005e-05, 'epoch': 1.07}\n",
      "{'loss': 0.7215, 'learning_rate': 3.3e-05, 'epoch': 1.1}\n",
      "{'loss': 0.7029, 'learning_rate': 3.4000000000000007e-05, 'epoch': 1.14}\n",
      "{'loss': 0.6926, 'learning_rate': 3.5e-05, 'epoch': 1.17}\n",
      "{'loss': 0.7228, 'learning_rate': 3.6e-05, 'epoch': 1.2}\n",
      "{'loss': 0.7589, 'learning_rate': 3.7e-05, 'epoch': 1.24}\n",
      "{'loss': 0.6455, 'learning_rate': 3.8e-05, 'epoch': 1.27}\n",
      "{'loss': 0.7121, 'learning_rate': 3.9000000000000006e-05, 'epoch': 1.3}\n",
      "{'loss': 0.6881, 'learning_rate': 4e-05, 'epoch': 1.34}\n",
      "{'loss': 0.6542, 'learning_rate': 4.1e-05, 'epoch': 1.37}\n",
      "{'loss': 0.7385, 'learning_rate': 4.2e-05, 'epoch': 1.4}\n",
      "{'loss': 0.6758, 'learning_rate': 4.3e-05, 'epoch': 1.44}\n",
      "{'loss': 0.7249, 'learning_rate': 4.4000000000000006e-05, 'epoch': 1.47}\n",
      "{'loss': 0.7372, 'learning_rate': 4.5e-05, 'epoch': 1.51}\n",
      "{'loss': 0.6204, 'learning_rate': 4.600000000000001e-05, 'epoch': 1.54}\n",
      "{'loss': 0.6906, 'learning_rate': 4.7e-05, 'epoch': 1.57}\n",
      "{'loss': 0.6862, 'learning_rate': 4.8e-05, 'epoch': 1.61}\n",
      "{'loss': 0.5954, 'learning_rate': 4.9e-05, 'epoch': 1.64}\n",
      "{'loss': 0.6984, 'learning_rate': 5e-05, 'epoch': 1.67}\n",
      "{'loss': 0.5927, 'learning_rate': 4.8740554156171286e-05, 'epoch': 1.71}\n",
      "{'loss': 0.6374, 'learning_rate': 4.748110831234257e-05, 'epoch': 1.74}\n",
      "{'loss': 0.6681, 'learning_rate': 4.622166246851385e-05, 'epoch': 1.77}\n",
      "{'loss': 0.6384, 'learning_rate': 4.496221662468514e-05, 'epoch': 1.81}\n",
      "{'loss': 0.6321, 'learning_rate': 4.370277078085643e-05, 'epoch': 1.84}\n",
      "{'loss': 0.6314, 'learning_rate': 4.244332493702771e-05, 'epoch': 1.87}\n",
      "{'loss': 0.6332, 'learning_rate': 4.1183879093198994e-05, 'epoch': 1.91}\n",
      "{'loss': 0.6037, 'learning_rate': 3.992443324937028e-05, 'epoch': 1.94}\n",
      "{'loss': 0.6134, 'learning_rate': 3.866498740554156e-05, 'epoch': 1.97}\n",
      "{'loss': 0.6179, 'learning_rate': 3.7405541561712845e-05, 'epoch': 2.01}\n",
      "{'loss': 0.6262, 'learning_rate': 3.614609571788413e-05, 'epoch': 2.04}\n",
      "{'loss': 0.6341, 'learning_rate': 3.488664987405542e-05, 'epoch': 2.07}\n",
      "{'loss': 0.6295, 'learning_rate': 3.36272040302267e-05, 'epoch': 2.11}\n",
      "{'loss': 0.6977, 'learning_rate': 3.2367758186397986e-05, 'epoch': 2.14}\n",
      "{'loss': 0.6369, 'learning_rate': 3.1108312342569276e-05, 'epoch': 2.17}\n",
      "{'loss': 0.6305, 'learning_rate': 2.9848866498740557e-05, 'epoch': 2.21}\n",
      "{'loss': 0.6896, 'learning_rate': 2.858942065491184e-05, 'epoch': 2.24}\n",
      "{'loss': 0.6777, 'learning_rate': 2.7329974811083124e-05, 'epoch': 2.27}\n",
      "{'loss': 0.6182, 'learning_rate': 2.607052896725441e-05, 'epoch': 2.31}\n",
      "{'loss': 0.6125, 'learning_rate': 2.4811083123425694e-05, 'epoch': 2.34}\n",
      "{'loss': 0.6068, 'learning_rate': 2.3551637279596978e-05, 'epoch': 2.37}\n",
      "{'loss': 0.6158, 'learning_rate': 2.2292191435768265e-05, 'epoch': 2.41}\n",
      "{'loss': 0.6588, 'learning_rate': 2.103274559193955e-05, 'epoch': 2.44}\n",
      "{'loss': 0.6143, 'learning_rate': 1.9773299748110832e-05, 'epoch': 2.47}\n",
      "{'loss': 0.6742, 'learning_rate': 1.8513853904282116e-05, 'epoch': 2.51}\n",
      "{'loss': 0.6313, 'learning_rate': 1.72544080604534e-05, 'epoch': 2.54}\n",
      "{'loss': 0.5624, 'learning_rate': 1.5994962216624686e-05, 'epoch': 2.58}\n",
      "{'loss': 0.6563, 'learning_rate': 1.4735516372795972e-05, 'epoch': 2.61}\n",
      "{'loss': 0.5984, 'learning_rate': 1.3476070528967255e-05, 'epoch': 2.64}\n",
      "{'loss': 0.5729, 'learning_rate': 1.2216624685138539e-05, 'epoch': 2.68}\n",
      "{'loss': 0.6715, 'learning_rate': 1.0957178841309824e-05, 'epoch': 2.71}\n",
      "{'loss': 0.6358, 'learning_rate': 9.69773299748111e-06, 'epoch': 2.74}\n",
      "{'loss': 0.6078, 'learning_rate': 8.438287153652395e-06, 'epoch': 2.78}\n",
      "{'loss': 0.5873, 'learning_rate': 7.178841309823678e-06, 'epoch': 2.81}\n",
      "{'loss': 0.6193, 'learning_rate': 5.919395465994963e-06, 'epoch': 2.84}\n",
      "{'loss': 0.5756, 'learning_rate': 4.659949622166247e-06, 'epoch': 2.88}\n",
      "{'loss': 0.5884, 'learning_rate': 3.400503778337532e-06, 'epoch': 2.91}\n",
      "{'loss': 0.5875, 'learning_rate': 2.1410579345088163e-06, 'epoch': 2.94}\n",
      "{'loss': 0.5597, 'learning_rate': 8.816120906801008e-07, 'epoch': 2.98}\n",
      "{'train_runtime': 167.5821, 'train_samples_per_second': 170.836, 'train_steps_per_second': 5.353, 'train_loss': 0.736845396035491, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The following untracked files were present in the workspace before saving but will not be included in the experiment commit:\n",
      "\texperiment-tracking-with-dvc.ipynb, experiment-tracking-old.ipynb, results/checkpoint-500/rng_state.pth, results/checkpoint-500/tokenizer_config.json, results/checkpoint-500/special_tokens_map.json, results/checkpoint-500/optimizer.pt, results/checkpoint-500/config.json, results/checkpoint-500/scheduler.pt, results/checkpoint-500/tokenizer.json, results/checkpoint-500/training_args.bin, results/checkpoint-500/vocab.txt, results/checkpoint-500/pytorch_model.bin, results/checkpoint-500/trainer_state.json\n",
      "WARNING:dvc.repo.experiments.save:The following untracked files were present in the workspace before saving but will not be included in the experiment commit:\n",
      "\texperiment-tracking-with-dvc.ipynb, experiment-tracking-old.ipynb, results/checkpoint-500/rng_state.pth, results/checkpoint-500/tokenizer_config.json, results/checkpoint-500/special_tokens_map.json, results/checkpoint-500/optimizer.pt, results/checkpoint-500/config.json, results/checkpoint-500/scheduler.pt, results/checkpoint-500/tokenizer.json, results/checkpoint-500/training_args.bin, results/checkpoint-500/vocab.txt, results/checkpoint-500/pytorch_model.bin, results/checkpoint-500/trainer_state.json\n",
      "INFO:dvclive:To run with DVC, add this to /Users/pupa/sarg/experiment-tracking-dvc/dvc.yaml:\n",
      "stages:\n",
      "  dvclive:\n",
      "    cmd: <python my_code_file.py my_args>\n",
      "    deps:\n",
      "    - <my_code_file.py>\n",
      "    outs:\n",
      "    - dvclive/metrics.json:\n",
      "        cache: false\n",
      "    - dvclive/plots:\n",
      "        cache: false\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=897, training_loss=0.736845396035491, metrics={'train_runtime': 167.5821, 'train_samples_per_second': 170.836, 'train_steps_per_second': 5.353, 'train_loss': 0.736845396035491, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.9960,  0.0771,  2.4874]], device='mps:0',\n",
      "       grad_fn=<LinearBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Test on user sample\n",
    "sample = \"BITCOIN is going to the moon\"\n",
    "inputs = tokenizer(sample, return_tensors=\"pt\")\n",
    "\n",
    "# Get the prediction\n",
    "print(model(**inputs.to(device))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This means that the model is predicting positive sentiment for this sample"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the tokenizer and the model\n",
    "checkpoint = \"ProsusAI/finbert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3, ignore_mismatched_sizes=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                                      # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                               # training arguments, defined above\n",
    "    train_dataset=tokenized_dataset[\"train\"],         # training dataset\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],     # evaluation dataset\n",
    "    data_collator=data_collator,                      # data collator\n",
    "    tokenizer=tokenizer,                              # tokenizer\n",
    "    callbacks=[DVCLiveCallback(save_dvc_exp=True)],   # DVC callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pupa/sarg/experiment-tracking-dvc/venv/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c6b14b0b34472ebce18a3c674f250c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/897 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3807, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.03}\n",
      "{'loss': 1.3822, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.07}\n",
      "{'loss': 1.2508, 'learning_rate': 3e-06, 'epoch': 0.1}\n",
      "{'loss': 1.0582, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.13}\n",
      "{'loss': 0.8108, 'learning_rate': 5e-06, 'epoch': 0.17}\n",
      "{'loss': 0.8294, 'learning_rate': 6e-06, 'epoch': 0.2}\n",
      "{'loss': 0.7439, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.23}\n",
      "{'loss': 0.6839, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.27}\n",
      "{'loss': 0.6834, 'learning_rate': 9e-06, 'epoch': 0.3}\n",
      "{'loss': 0.6931, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 0.6936, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.37}\n",
      "{'loss': 0.7056, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "{'loss': 0.6868, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.43}\n",
      "{'loss': 0.6758, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.47}\n",
      "{'loss': 0.6426, 'learning_rate': 1.5e-05, 'epoch': 0.5}\n",
      "{'loss': 0.5865, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.54}\n",
      "{'loss': 0.5807, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.57}\n",
      "{'loss': 0.5594, 'learning_rate': 1.8e-05, 'epoch': 0.6}\n",
      "{'loss': 0.5789, 'learning_rate': 1.9e-05, 'epoch': 0.64}\n",
      "{'loss': 0.5971, 'learning_rate': 2e-05, 'epoch': 0.67}\n",
      "{'loss': 0.6057, 'learning_rate': 2.1e-05, 'epoch': 0.7}\n",
      "{'loss': 0.6089, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.74}\n",
      "{'loss': 0.4842, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.77}\n",
      "{'loss': 0.5324, 'learning_rate': 2.4e-05, 'epoch': 0.8}\n",
      "{'loss': 0.5528, 'learning_rate': 2.5e-05, 'epoch': 0.84}\n",
      "{'loss': 0.4947, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.87}\n",
      "{'loss': 0.527, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.9}\n",
      "{'loss': 0.5051, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.94}\n",
      "{'loss': 0.4212, 'learning_rate': 2.9e-05, 'epoch': 0.97}\n",
      "{'loss': 0.3718, 'learning_rate': 3e-05, 'epoch': 1.0}\n",
      "{'loss': 0.4073, 'learning_rate': 3.1e-05, 'epoch': 1.04}\n",
      "{'loss': 0.3948, 'learning_rate': 3.2000000000000005e-05, 'epoch': 1.07}\n",
      "{'loss': 0.4391, 'learning_rate': 3.3e-05, 'epoch': 1.1}\n",
      "{'loss': 0.3947, 'learning_rate': 3.4000000000000007e-05, 'epoch': 1.14}\n",
      "{'loss': 0.3264, 'learning_rate': 3.5e-05, 'epoch': 1.17}\n",
      "{'loss': 0.3467, 'learning_rate': 3.6e-05, 'epoch': 1.2}\n",
      "{'loss': 0.4078, 'learning_rate': 3.7e-05, 'epoch': 1.24}\n",
      "{'loss': 0.3368, 'learning_rate': 3.8e-05, 'epoch': 1.27}\n",
      "{'loss': 0.3278, 'learning_rate': 3.9000000000000006e-05, 'epoch': 1.3}\n",
      "{'loss': 0.37, 'learning_rate': 4e-05, 'epoch': 1.34}\n",
      "{'loss': 0.3112, 'learning_rate': 4.1e-05, 'epoch': 1.37}\n",
      "{'loss': 0.4189, 'learning_rate': 4.2e-05, 'epoch': 1.4}\n",
      "{'loss': 0.4047, 'learning_rate': 4.3e-05, 'epoch': 1.44}\n",
      "{'loss': 0.3662, 'learning_rate': 4.4000000000000006e-05, 'epoch': 1.47}\n",
      "{'loss': 0.3708, 'learning_rate': 4.5e-05, 'epoch': 1.51}\n",
      "{'loss': 0.3597, 'learning_rate': 4.600000000000001e-05, 'epoch': 1.54}\n",
      "{'loss': 0.2935, 'learning_rate': 4.7e-05, 'epoch': 1.57}\n",
      "{'loss': 0.339, 'learning_rate': 4.8e-05, 'epoch': 1.61}\n",
      "{'loss': 0.2959, 'learning_rate': 4.9e-05, 'epoch': 1.64}\n",
      "{'loss': 0.3616, 'learning_rate': 5e-05, 'epoch': 1.67}\n",
      "{'loss': 0.3464, 'learning_rate': 4.8740554156171286e-05, 'epoch': 1.71}\n",
      "{'loss': 0.3379, 'learning_rate': 4.748110831234257e-05, 'epoch': 1.74}\n",
      "{'loss': 0.3117, 'learning_rate': 4.622166246851385e-05, 'epoch': 1.77}\n",
      "{'loss': 0.3141, 'learning_rate': 4.496221662468514e-05, 'epoch': 1.81}\n",
      "{'loss': 0.3813, 'learning_rate': 4.370277078085643e-05, 'epoch': 1.84}\n",
      "{'loss': 0.3564, 'learning_rate': 4.244332493702771e-05, 'epoch': 1.87}\n",
      "{'loss': 0.3726, 'learning_rate': 4.1183879093198994e-05, 'epoch': 1.91}\n",
      "{'loss': 0.3298, 'learning_rate': 3.992443324937028e-05, 'epoch': 1.94}\n",
      "{'loss': 0.3167, 'learning_rate': 3.866498740554156e-05, 'epoch': 1.97}\n",
      "{'loss': 0.3058, 'learning_rate': 3.7405541561712845e-05, 'epoch': 2.01}\n",
      "{'loss': 0.2008, 'learning_rate': 3.614609571788413e-05, 'epoch': 2.04}\n",
      "{'loss': 0.1523, 'learning_rate': 3.488664987405542e-05, 'epoch': 2.07}\n",
      "{'loss': 0.1854, 'learning_rate': 3.36272040302267e-05, 'epoch': 2.11}\n",
      "{'loss': 0.1885, 'learning_rate': 3.2367758186397986e-05, 'epoch': 2.14}\n",
      "{'loss': 0.2303, 'learning_rate': 3.1108312342569276e-05, 'epoch': 2.17}\n",
      "{'loss': 0.1922, 'learning_rate': 2.9848866498740557e-05, 'epoch': 2.21}\n",
      "{'loss': 0.1515, 'learning_rate': 2.858942065491184e-05, 'epoch': 2.24}\n",
      "{'loss': 0.2679, 'learning_rate': 2.7329974811083124e-05, 'epoch': 2.27}\n",
      "{'loss': 0.2044, 'learning_rate': 2.607052896725441e-05, 'epoch': 2.31}\n",
      "{'loss': 0.2034, 'learning_rate': 2.4811083123425694e-05, 'epoch': 2.34}\n",
      "{'loss': 0.1645, 'learning_rate': 2.3551637279596978e-05, 'epoch': 2.37}\n",
      "{'loss': 0.1584, 'learning_rate': 2.2292191435768265e-05, 'epoch': 2.41}\n",
      "{'loss': 0.1495, 'learning_rate': 2.103274559193955e-05, 'epoch': 2.44}\n",
      "{'loss': 0.1076, 'learning_rate': 1.9773299748110832e-05, 'epoch': 2.47}\n",
      "{'loss': 0.1229, 'learning_rate': 1.8513853904282116e-05, 'epoch': 2.51}\n",
      "{'loss': 0.1072, 'learning_rate': 1.72544080604534e-05, 'epoch': 2.54}\n",
      "{'loss': 0.1368, 'learning_rate': 1.5994962216624686e-05, 'epoch': 2.58}\n",
      "{'loss': 0.1798, 'learning_rate': 1.4735516372795972e-05, 'epoch': 2.61}\n",
      "{'loss': 0.1253, 'learning_rate': 1.3476070528967255e-05, 'epoch': 2.64}\n",
      "{'loss': 0.1358, 'learning_rate': 1.2216624685138539e-05, 'epoch': 2.68}\n",
      "{'loss': 0.1621, 'learning_rate': 1.0957178841309824e-05, 'epoch': 2.71}\n",
      "{'loss': 0.1762, 'learning_rate': 9.69773299748111e-06, 'epoch': 2.74}\n",
      "{'loss': 0.1635, 'learning_rate': 8.438287153652395e-06, 'epoch': 2.78}\n",
      "{'loss': 0.1709, 'learning_rate': 7.178841309823678e-06, 'epoch': 2.81}\n",
      "{'loss': 0.1244, 'learning_rate': 5.919395465994963e-06, 'epoch': 2.84}\n",
      "{'loss': 0.1158, 'learning_rate': 4.659949622166247e-06, 'epoch': 2.88}\n",
      "{'loss': 0.1394, 'learning_rate': 3.400503778337532e-06, 'epoch': 2.91}\n",
      "{'loss': 0.1113, 'learning_rate': 2.1410579345088163e-06, 'epoch': 2.94}\n",
      "{'loss': 0.126, 'learning_rate': 8.816120906801008e-07, 'epoch': 2.98}\n",
      "{'train_runtime': 1186.6768, 'train_samples_per_second': 24.125, 'train_steps_per_second': 0.756, 'train_loss': 0.4050648745352874, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The following untracked files were present in the workspace before saving but will not be included in the experiment commit:\n",
      "\texperiment-tracking-with-dvc.ipynb, experiment-tracking-old.ipynb, results/checkpoint-500/rng_state.pth, results/checkpoint-500/tokenizer_config.json, results/checkpoint-500/special_tokens_map.json, results/checkpoint-500/optimizer.pt, results/checkpoint-500/config.json, results/checkpoint-500/scheduler.pt, results/checkpoint-500/tokenizer.json, results/checkpoint-500/training_args.bin, results/checkpoint-500/vocab.txt, results/checkpoint-500/pytorch_model.bin, results/checkpoint-500/trainer_state.json\n",
      "WARNING:dvc.repo.experiments.save:The following untracked files were present in the workspace before saving but will not be included in the experiment commit:\n",
      "\texperiment-tracking-with-dvc.ipynb, experiment-tracking-old.ipynb, results/checkpoint-500/rng_state.pth, results/checkpoint-500/tokenizer_config.json, results/checkpoint-500/special_tokens_map.json, results/checkpoint-500/optimizer.pt, results/checkpoint-500/config.json, results/checkpoint-500/scheduler.pt, results/checkpoint-500/tokenizer.json, results/checkpoint-500/training_args.bin, results/checkpoint-500/vocab.txt, results/checkpoint-500/pytorch_model.bin, results/checkpoint-500/trainer_state.json\n",
      "INFO:dvclive:To run with DVC, add this to /Users/pupa/sarg/experiment-tracking-dvc/dvc.yaml:\n",
      "stages:\n",
      "  dvclive:\n",
      "    cmd: <python my_code_file.py my_args>\n",
      "    deps:\n",
      "    - <my_code_file.py>\n",
      "    outs:\n",
      "    - dvclive/metrics.json:\n",
      "        cache: false\n",
      "    - dvclive/plots:\n",
      "        cache: false\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=897, training_loss=0.4050648745352874, metrics={'train_runtime': 1186.6768, 'train_samples_per_second': 24.125, 'train_steps_per_second': 0.756, 'train_loss': 0.4050648745352874, 'epoch': 3.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
